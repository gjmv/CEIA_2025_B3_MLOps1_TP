# CEIA_2025_B3_MLOps1_TP

Curso de Especializaci칩n en Inteligencia Artificial  
A침o 2025  
Bimestre 3  

## Materia: Operaciones de Aprendizaje Autom치tico 1  

## Docente:
* Facundo Lucianna

## Integrantes:
* Mendoza Dante
* Vi침as Gustavo


## Iniciar servicios

```bash
docker compose --profile all up
```

   - Apache Airflow: http://localhost:8080
   - MLflow: http://localhost:5001
   - MinIO: http://localhost:9001 (ventana de administraci칩n de Buckets)
   - API: http://localhost:8800/
   - Documentaci칩n de la API: http://localhost:8800/docs

## Apagar los servicios

Detener los servicios:

```bash
docker compose --profile all down
```

Detener los servicios y eliminar toda la infraestructura (liberando espacio en disco):

```bash
docker compose --profile all down --rmi all --volumes
```
Nota: Si haces esto, perder치s todo en los buckets y bases de datos.

# Descripci칩n del proyecto

Al iniciar los servicios por primera vez, tendremos el ambiente totalmente vac칤o.  

Para comenzar, debemos ejecutar en Airflow el DAG/ETL (o establecer alg칰n criterio de ejecuci칩n autom치tica). Esto cargar치 los datos de cr칤menes de Chicago en nuestro bucket "data" de S3 en la ruta "chicago/crimes/2024", registrando en MLFlow el proceso dentro del experimento "Chicago Crimes 2024".  
Dentro del bucket, se guarda el dataset original, el de columnas preprocesadas (sin transformaci칩n aun) y los sets de train y test, separados en features y target. Este 칰ltimo ubicado en una subcarpeta "final".
Tambi칠n se guarda informaci칩n de las columnas (preprocesadas) y el pipeline para transformaci칩n de las mismas. Esta informaci칩n se encuentra en el mismo bucket, en la ruta "/chicago/crimes/data_info".

Una vez cargados los datos, podremos realizar el entrenamiento de nuestros modelos a trav칠s de 2 notebooks.  
Utilizaremos 2 modelos creados en la materia Aprendizaje de M치quina.  
Uno de ellos, Decision Tree Classifier, con b칰squeda de hiperpar치metros mediante optuna, disponible en la notebook notebook_example\experiment_DTC.ipynb.  
El otro, un modelo sencillo de Linear Discriminant Analysis, disponible en la notebook notebook_example\experiment_LDA.ipynb.

Los requisitos para la ejecuci칩n de las notebooks se encuentran en "notebook_example\requirements.txt" o como proyecto de uv en "notebook_example\pyproject.toml"

Al ejecutar cada una de las notebooks, el proceso descargar치 los archivos de entrenamiento, entrenar치 el modelo y calcular치 las m칠tricas contra el set de test. Toda esta informaci칩n se guardar치 en MLFlow en el experimento llamado "Chicago Crimes 2024".  
Tambi칠n se registrar치n los modelos productivos, que ser치 utilizado en la API para predecir.  

La API, implementada mediante FastAPI, recibe un POST en el endpoint /predict, con las features como datos.  
Este endpoint internamente realiza la validaci칩n y transformaci칩n de variables, y luego aplica los modelos obtenidos desde MLFlow (con posibilidad de usar una versi칩n embebida local en caso de no poder conectarse). Como resultado obtenemos la predicci칩n realizada con ambos modelos.  

Ejemplo de llamada al endpoint:
```
curl -X 'POST' \
  'http://localhost:8800/predict/' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "features": {
    "arrest": false,
    "beat": 412,
    "community_area": 46,
    "description": "THEFT / RECOVERY - AUTOMOBILE",
    "dia_mes": 4,
    "dia_semana": 1,
    "district": 4,
    "domestic": false,
    "hora": 5,
    "iucr": "0930",
    "latitude": 41.743747398,
    "location_description": "STREET",
    "longitude": -87.566115082,
    "mes": 6,
    "primary_type": "MOTOR VEHICLE THEFT",
    "ward": 7
  }
}'
```

Respuesta esperada:
```
{"dtc_fbi_code_output":"07","lda_fbi_code_output":"07"}
```

Se puede consultar la documentaci칩n de la API en http://localhost:8800/docs

### Datos de prueba
Se pueden encontrar datos para probar el endpoint de la API en la notebook "notebook_example\samples.ipynb".  
Esta notebook cargar치 el dataset de columnas preprocesadas (sin transformaci칩n) y mostrar치 un registro de este dataset, junto al valor esperado (target).  
Tambi칠n contiene un ejemplo con uso de redis como cache intermedia, donde la predicci칩n se busca primero en redis y de no encontrarse se invoca la API para generarla.

## Nota
El proyecto realiz칩 en Windows 11, aunque tambi칠n fue probado en Ubuntu 24, sin encontrar inconvenientes a la hora de su ejecuci칩n (sin necesidad de cambiar el AIRFLOW_UID).  
Igualmente se recomienda su ejecuci칩n en Windows 11, ante la posibilidad de problemas de compatibilidad desconocidos en otros entornos.

## 游늷 Arquitectura general del sistema
```mermaid
flowchart TB
    subgraph Docker_Compose
        A[Apache Airflow]
        B["MinIO S3"]
        C[MLflow]
        D[FastAPI]
        H[Postgres DB]
    end

    %% Relaciones principales
    A --> E["Data Lake - Crimes Chicago"]
    A --> B
    A --> C
    A <--> H
    C <--> H
    D --> C
    D --> B
    C --> F["Registro de modelos"]
    D --> G["Cliente / App"]

    %% Estilos
    style A fill:#1f77b4,stroke:#000,stroke-width:2px,color:#fff
    style B fill:#9467bd,stroke:#000,stroke-width:2px,color:#fff
    style C fill:#2ca02c,stroke:#000,stroke-width:2px,color:#fff
    style D fill:#ff7f0e,stroke:#000,stroke-width:2px,color:#fff
    style E fill:#8c564b,stroke:#000,stroke-width:2px,color:#fff
    style F fill:#17becf,stroke:#000,stroke-width:2px,color:#fff
    style G fill:#d62728,stroke:#000,stroke-width:2px,color:#fff
    style H fill:#7f7f7f,stroke:#000,stroke-width:2px,color:#fff
```

## 游늷 Ciclo de vida del modelo
```mermaid
flowchart LR
    A["Data Lake - Crimes Chicago"] --> B["Airflow ETL"]
    B <--> C["MinIO (Almacenamiento)"]
    C --> D["Train/Test Split"]
    D --> E["Entrenamiento (Notebook/Script)"]
    E --> F["MLflow Tracking"]
    F --> G["MLflow Registro de Modelos"]
    G --> H["FastAPI Predicci칩n"]
    H --> I["Predicci칩n al usuario"]

    %% Integraci칩n con Postgres
    F <---> J["Postgres (Metadatos MLflow)"]

    %% Estilos
    style A fill:#8c564b,stroke:#000,stroke-width:2px,color:#fff
    style B fill:#1f77b4,stroke:#000,stroke-width:2px,color:#fff
    style C fill:#9467bd,stroke:#000,stroke-width:2px,color:#fff
    style D fill:#2ca02c,stroke:#000,stroke-width:2px,color:#fff
    style E fill:#bcbd22,stroke:#000,stroke-width:2px,color:#fff
    style F fill:#2ca02c,stroke:#000,stroke-width:2px,color:#fff
    style G fill:#17becf,stroke:#000,stroke-width:2px,color:#fff
    style H fill:#ff7f0e,stroke:#000,stroke-width:2px,color:#fff
    style I fill:#d62728,stroke:#000,stroke-width:2px,color:#fff
    style J fill:#7f7f7f,stroke:#000,stroke-width:2px,color:#fff
```

## 游늷 Pipeline dentro de Airflow (DAG)
```mermaid
flowchart TD
    %% --- DAG de Airflow ---
    subgraph Airflow_DAG["Airflow DAG"]
        Start["Start / Trigger DAG"] --> Ingest["Ingest Data"]
        Ingest --> Preprocess["Preprocess Data"]
    end

    %% --- Proceso en Notebooks ---
    subgraph Notebooks["Notebooks"]
        Preprocess --> Train["Train Model"]
        Train --> Evaluate["Evaluate Model"]

        Evaluate --> |si es bueno| Register_Model["Register Model"]
        Evaluate --> |si es malo| Train

        Register_Model --> End["Finish / Deploy"]
    end

    %% Estilos
    style Start fill:#1f77b4,stroke:#000,stroke-width:2px,color:#fff
    style Ingest fill:#17becf,stroke:#000,stroke-width:2px,color:#fff
    style Preprocess fill:#ff7f0e,stroke:#000,stroke-width:2px,color:#fff
    style Train fill:#2ca02c,stroke:#000,stroke-width:2px,color:#fff
    style Evaluate fill:#bcbd22,stroke:#000,stroke-width:2px,color:#fff
    style Register_Model fill:#9467bd,stroke:#000,stroke-width:2px,color:#fff
    style End fill:#d62728,stroke:#000,stroke-width:2px,color:#fff
```
